---
date: 2020-02-01 16:15:06
categories:
   - 机器学习
tags:
   - 吴恩达视频笔记
mathjax: true

---


#### 训练集、测试集
在预测过程中发现存在很大的错误，我们会考虑使用以下的方法来解决
1. 获取更多的训练样本
2. 减少训练的特征
3. 增加训练的特征
4. 尝试多项式特征
5. 增加或减少λ

<!--more-->


一个假设可能对训练样本的误差较小，但其实际上仍然不准确(因为过度拟合)。
因此，为了评估假设，我们将给定训练样本数据集分成两组：训练集和测试集。 通常，训练集(training set)包含70％的数据，测试集(test set)包含剩余的30％。
使用如下：

$$
1.\; learn \; \Theta \; and \; minimize \; J_{test}(\Theta) \; using \; the \; training \; set 

2.\;compute \; the\;  test \; set \; error \; J_{test}(\Theta)

$$

测试集的误差
对于线性回归：
$$
 J_{test}(\Theta)=\frac{1}{2m_{test}} \quad \sum_{i=1}^{m_{test}}{(h_\Theta(x_{test}^{(i)})-y_{test}^{(i)})^2}
$$
 
对于分类-误分类错误（又名0/1错误分类错误）
$$
err(h_\Theta(x),y) = \frac{1}{0}   \; if \; h_\Theta(x) > 0.5 \; and \; y = 0  \; or \;  h_\Theta(x) < 0.5 \; and \; y = 1

$$
测试集的平均测试错误为：
$$
Test \; error =\frac{1}{m_{test}}  err(h_\Theta(x_{test}^{(i)}),y_{test}^{(i)})
$$
 这为我们提供了错误分类的测试数据的比例。



#### 训练集，交叉验证集，测试集
学习算法很好地适合训练集，并不意味着它是一个很好的假设。 它可能过度适应，因此对测试集的预测效果会很差。 训练参数的数据集上测量的误差将低于任何其他数据集的误差。

鉴于许多具有不同多项式度的模型，我们可以使用系统方法来识别“最佳”函数。 为了选择假设的模型，可以测试每个多项式的次数并查看错误结果。

将数据集分解为三组的一种方法是：
- 训练集：60%
- 交叉验证集：20%
- 测试集：20%

我们现在可以使用以下方法对三个不同的集合计算三个的错误值：
- 使用训练集，对每个多项式，优化Θ的参数。
- 使用交叉验证集，找到具有最小误差的多项式。
- 使用测试集，来估计具有较低误差的多项式误差。

#### 偏差 vs. 方差
多项式次数与欠拟合和过拟合之间的关系。
<br/>
高偏差是欠拟合的，高方差是过拟合。
<br/>
随着我们增加多项式的次数d，训练误差将趋于减小。
<br/>
同时，随着我们将d增加到某一个点，交叉验证误差将趋于减少。<br/>
然后随着d的增加它会增加，形成一个凸曲线。
<br/>

总结：
- 高偏差：训练误差，交叉验证误差都很大，且 交叉误差 约等于 训练误差 
- 高方差：训练误差会变小，而交叉误差会很大，且 交叉误差 > 训练误差 



#### 正则化与偏差、方差
正则化参数很大，趋近于欠拟合  <br/>
正则化参数接近0，趋近于欠拟合


1. 创建一个参数集合，λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24}
2. 创建一组具有不同次数的多项式或任何其他变体的模型。
3. 遍历参数集合，对每一个参数，每一个模型都进行学习并获得一些𝚯。
4. 在不使用正则参数的情况下，用学习获得的𝚯计算交叉验证的误差
5. 选择在交叉验证集上产生最小误差的最佳组合。
6. 使用最佳组合Θ和λ，将其应用于问题的解决𝐉。

#### 下一步需要做什么
##### 我们的决策过程可细分如下：
1. 获得更多训练样本：修复高方差
2. 尝试使用较少的特征：修复高方差
3. 增加特征：修复高偏差
4. 添加多项式特征：修复高偏差
5. 减少λ：修复高偏差
6. 增加λ：修正高方差

##### 诊断神经网络
1. 参数较少的神经网络容易出现欠拟合。它的计算成本也更低。
2. 具有更多参数的大型神经网络容易过度拟合。它的计算成本也很高。
在这种情况下，可以使用正则化（增加λ）来解决过度拟合问题。

使用单个隐藏层是一个很好的启动默认值。
可以使用交叉验证集在多个隐藏层上训练您的神经网络。
然后，可以选择性能最佳的那个。

##### 模型复杂性效应
1. 低阶多项式（lowmodelcomplexity）具有高偏差和低方差。在这种情况下，模型的拟合非常一致。
2. 高阶多项式（高模型复杂度）非常适合训练数据，测试数据非常差。这些对训练数据的偏差很小，但方差很大。
3. 实际上，我们希望在两者之间选择一个模型，它可以很好地推广，但也可以很好地拟合数据。
